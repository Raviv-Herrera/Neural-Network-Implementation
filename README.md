# Neural-Network-Implementation
An implementation from scratch (no tf or torch) of fully conected NN 

## Description
In this project I present my own implementation of a fully conected NN and using it on MNIST benchmark dataset.
The network contains Dense layers and 3 different regularization methods to prevent over-fitting (Dropout layer, L2 , early stopping).
Since the task of this network is to solve a classification problem the appropriate chosen loss function is "Categorical-Cross-Entropy"
In addition, at the end of the process there are info graphs for the optimization methods for 5 different learning rates and the matching validation graphs. 

There is an option to increase the original dataset by augmentation methods, provided by Keras.

I hope you find my implementation useful. 


